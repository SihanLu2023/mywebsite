---
title: "Session 2: Homework 1"
author: "Group 5: Arvind Sridhar, Sihan Lu, Sneha Ramteke, Wei Wu, Ioana-Daria Gherghelas, Sofya Lyuleva"
date: "2022-09-20"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />


<div id="rents-in-san-francsisco-2000-2018" class="section level1">
<h1>Rents in San Francsisco 2000-2018</h1>
<p><a href="https://www.katepennington.org/data">Kate Pennington</a> created a panel of historic Craigslist rents by scraping posts archived by the Wayback Machine. You can read more about her work here</p>
<p>In our case, we have a clean(ish) dataset with about 200K rows tht corresponf to Craigslist listings for renting properties in the greater SF area. The data dictionary is as follows</p>
<table>
<thead>
<tr class="header">
<th>variable</th>
<th>class</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>post_id</td>
<td>character</td>
<td>Unique ID</td>
</tr>
<tr class="even">
<td>date</td>
<td>double</td>
<td>date</td>
</tr>
<tr class="odd">
<td>year</td>
<td>double</td>
<td>year</td>
</tr>
<tr class="even">
<td>nhood</td>
<td>character</td>
<td>neighborhood</td>
</tr>
<tr class="odd">
<td>city</td>
<td>character</td>
<td>city</td>
</tr>
<tr class="even">
<td>county</td>
<td>character</td>
<td>county</td>
</tr>
<tr class="odd">
<td>price</td>
<td>double</td>
<td>price in USD</td>
</tr>
<tr class="even">
<td>beds</td>
<td>double</td>
<td>n of beds</td>
</tr>
<tr class="odd">
<td>baths</td>
<td>double</td>
<td>n of baths</td>
</tr>
<tr class="even">
<td>sqft</td>
<td>double</td>
<td>square feet of rental</td>
</tr>
<tr class="odd">
<td>room_in_apt</td>
<td>double</td>
<td>room in apartment</td>
</tr>
<tr class="even">
<td>address</td>
<td>character</td>
<td>address</td>
</tr>
<tr class="odd">
<td>lat</td>
<td>double</td>
<td>latitude</td>
</tr>
<tr class="even">
<td>lon</td>
<td>double</td>
<td>longitude</td>
</tr>
<tr class="odd">
<td>title</td>
<td>character</td>
<td>title of listing</td>
</tr>
<tr class="even">
<td>descr</td>
<td>character</td>
<td>description</td>
</tr>
<tr class="odd">
<td>details</td>
<td>character</td>
<td>additional details</td>
</tr>
</tbody>
</table>
<p>The dataset was used in a recent <a href="https://github.com/rfordatascience/tidytuesday">tidyTuesday</a> project.</p>
<pre class="r"><code># download directly off tidytuesdaygithub repo

rent &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-05/rent.csv&#39;)</code></pre>
<p>What are the variable types? Do they all correspond to what they really are? Which variables have most missing values?</p>
<blockquote>
<p>There are mainly two types of variables double(numeric) and character(categorical). All the columns except date and year have correct datatypes. Dates can be converted to time data types to facilitate time series analysis. Description variable has the most missing values.</p>
</blockquote>
<pre class="r"><code># YOUR CODE GOES HERE
skimr::skim(rent)</code></pre>
<table style="width: auto;" class="table table-condensed">
<caption>
(#tab:skim_data)Data summary
</caption>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
rent
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
200796
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
17
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
character
</td>
<td style="text-align:left;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
empty
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:right;">
whitespace
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
post_id
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
200796
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
nhood
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
43
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
167
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
city
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
104
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
county
</td>
<td style="text-align:right;">
1394
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
address
</td>
<td style="text-align:right;">
196888
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2869
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
title
</td>
<td style="text-align:right;">
2517
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
298
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
184961
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
descr
</td>
<td style="text-align:right;">
197542
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
16975
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3025
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
details
</td>
<td style="text-align:right;">
192780
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
595
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
7667
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
date
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
2.01e+07
</td>
<td style="text-align:right;">
44694.07
</td>
<td style="text-align:right;">
2.00e+07
</td>
<td style="text-align:right;">
2.01e+07
</td>
<td style="text-align:right;">
2.01e+07
</td>
<td style="text-align:right;">
2.01e+07
</td>
<td style="text-align:right;">
2.02e+07
</td>
<td style="text-align:left;">
▁▇▁▆▃
</td>
</tr>
<tr>
<td style="text-align:left;">
year
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
2.01e+03
</td>
<td style="text-align:right;">
4.48
</td>
<td style="text-align:right;">
2.00e+03
</td>
<td style="text-align:right;">
2.00e+03
</td>
<td style="text-align:right;">
2.01e+03
</td>
<td style="text-align:right;">
2.01e+03
</td>
<td style="text-align:right;">
2.02e+03
</td>
<td style="text-align:left;">
▁▇▁▆▃
</td>
</tr>
<tr>
<td style="text-align:left;">
price
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
2.14e+03
</td>
<td style="text-align:right;">
1427.75
</td>
<td style="text-align:right;">
2.20e+02
</td>
<td style="text-align:right;">
1.30e+03
</td>
<td style="text-align:right;">
1.80e+03
</td>
<td style="text-align:right;">
2.50e+03
</td>
<td style="text-align:right;">
4.00e+04
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
beds
</td>
<td style="text-align:right;">
6608
</td>
<td style="text-align:right;">
0.97
</td>
<td style="text-align:right;">
1.89e+00
</td>
<td style="text-align:right;">
1.08
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
1.00e+00
</td>
<td style="text-align:right;">
2.00e+00
</td>
<td style="text-align:right;">
3.00e+00
</td>
<td style="text-align:right;">
1.20e+01
</td>
<td style="text-align:left;">
▇▂▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
baths
</td>
<td style="text-align:right;">
158121
</td>
<td style="text-align:right;">
0.21
</td>
<td style="text-align:right;">
1.68e+00
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
1.00e+00
</td>
<td style="text-align:right;">
1.00e+00
</td>
<td style="text-align:right;">
2.00e+00
</td>
<td style="text-align:right;">
2.00e+00
</td>
<td style="text-align:right;">
8.00e+00
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
sqft
</td>
<td style="text-align:right;">
136117
</td>
<td style="text-align:right;">
0.32
</td>
<td style="text-align:right;">
1.20e+03
</td>
<td style="text-align:right;">
5000.22
</td>
<td style="text-align:right;">
8.00e+01
</td>
<td style="text-align:right;">
7.50e+02
</td>
<td style="text-align:right;">
1.00e+03
</td>
<td style="text-align:right;">
1.36e+03
</td>
<td style="text-align:right;">
9.00e+05
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
room_in_apt
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
1.00e+00
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
lat
</td>
<td style="text-align:right;">
193145
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
3.77e+01
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
3.36e+01
</td>
<td style="text-align:right;">
3.74e+01
</td>
<td style="text-align:right;">
3.78e+01
</td>
<td style="text-align:right;">
3.78e+01
</td>
<td style="text-align:right;">
4.04e+01
</td>
<td style="text-align:left;">
▁▁▅▇▁
</td>
</tr>
<tr>
<td style="text-align:left;">
lon
</td>
<td style="text-align:right;">
196484
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
-1.22e+02
</td>
<td style="text-align:right;">
0.78
</td>
<td style="text-align:right;">
-1.23e+02
</td>
<td style="text-align:right;">
-1.22e+02
</td>
<td style="text-align:right;">
-1.22e+02
</td>
<td style="text-align:right;">
-1.22e+02
</td>
<td style="text-align:right;">
-7.42e+01
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
</tbody>
</table>
<p>Make a plot that shows the top 20 cities in terms of % of classifieds between 2000-2018. You need to calculate the number of listings by city, and then convert that number to a %.</p>
<pre class="r"><code>#creating data
data1 &lt;- rent %&gt;% 
 filter((year&gt;= 2000) &amp; (year &lt;= 2018)) %&gt;% #filter for years 
 group_by(city) %&gt;%   #group at city level
 summarise(classifieds_city = count(city)) %&gt;% #number of listings by city
 mutate(classifieds = classifieds_city/sum(classifieds_city)) %&gt;% #% of classifieds
 slice_max(order_by = classifieds, n = 20) #select top 20 cities by % of classifieds

#plotting bargraph
plot1 &lt;- ggplot(data1, aes(x = classifieds, y = fct_reorder(city, classifieds, max))) + 
         geom_bar(stat = &#39;identity&#39;) + 
         scale_x_continuous(labels = scales::percent_format(accuracy = 1)) + 
         labs(title = &quot;Top 20 cities by % classifieds between 2000 to 2018&quot;, 
              subtitle = &quot;San Francisco contributes to more than quarter of the rent listings&quot;, 
              caption = &quot;Source: Pennington. Kate (2018). Bav Area Craigslist Rental Housing Posts 2000-2018&quot;,
              x = &quot;% Classifieds&quot;,
              y = &quot;City&quot;)

plot1</code></pre>
<p><img src="/blogs/homework1_files/figure-html/top_cities-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Make a plot that shows the evolution of median prices in San Francisco for 0, 1, 2, and 3 bedrooms listings. The final graph should look like this</p>
<pre class="r"><code># data creation
target &lt;- c(0, 1, 2, 3) # beds vector to filter
data2 &lt;- rent %&gt;% 
  filter((city == &quot;san francisco&quot;)&amp;(beds %in% target)) %&gt;% # filter by city and number of beds
  group_by(year, beds) %&gt;% # grouped at year and bed level
  summarise(median_price = median(price)) # calculate median price

# plot creation
plot2 &lt;- ggplot(data2, aes(x = year, y = median_price, colour = beds)) + 
         geom_line() + 
         facet_grid(~beds) + 
         theme(legend.position=&quot;none&quot;) +
         labs(title = &quot;Evolution of median prices in San Francisco for 0, 1, 2, and 3 bedrooms&quot;, 
              subtitle = &quot;Rent prices in San Francisco have been steadily rising over the years&quot;, 
              caption = &quot;Source: Pennington, Kate (2018). Bay Area Craigslist Rental Housing Posts, 2000-2018&quot;,
              x = &quot;Year&quot;,
              y = &quot;Median Price&quot;)

plot2</code></pre>
<p><img src="/blogs/homework1_files/figure-html/sf_median_prices-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Finally, make a plot that shows median rental prices for the top 12 cities in the Bay area. Your final graph should look like this</p>
<pre class="r"><code># code to extract top 12 cities
data5 &lt;- rent %&gt;% 
         group_by(city) %&gt;% # grouped at city level
         summarise(classifieds_city = count(city)) %&gt;% # number of listings by city
         mutate(classifieds = classifieds_city/sum(classifieds_city)) %&gt;% #% of listings by city
         slice_max(order_by = classifieds, n = 12) %&gt;% # select top 12 cities by % of listings
         pull(city) #extract

# data creation
data4 &lt;- rent %&gt;% 
         filter((beds == 1)&amp;(city %in% data5)) %&gt;% #filter for 1 bed and top 12 city
         group_by(city, year) %&gt;% #grouped at city and year level
         summarise(median_price = median(price)) #calculate median price

# plot graph
plot4 &lt;- ggplot(data4, aes(x = year, y = median_price, colour = city)) + 
         geom_line() + 
         facet_wrap(~city, nrow = 3) + 
         theme(legend.position=&quot;none&quot;) +
         labs(title = &quot;Median rent prices in top 12 cities in Bay Area&quot;, 
              subtitle = &quot;The rent prices in top 12 cities show increasing trend over the years&quot;,
              caption = &quot;Source: Pennington, Kate (2018). Bay Area Craigslist Rental Housing Posts, 2000-2018&quot;,
              x = &quot;Year&quot;,
              y = &quot;Median Price&quot;)

plot4</code></pre>
<p><img src="/blogs/homework1_files/figure-html/spirit_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>What can you infer from these plots? Don’t just explain what’s in the graph, but speculate or tell a short story (1-2 paragraphs max).</p>
<blockquote>
<p>The analysis above shows that San Francisco owns up more than quarter of the total rental listings in the Bay area. In particularly san francisco, we can see that the prices for different types of bedrooms all show increasing trends and as the number of beds increase the price trends get steeper signifying that rentals with more beds has more price increase over the years. The price increase may be attributed to factors like inflation and increasing demand.</p>
</blockquote>
</div>
<div id="analysis-of-movies--imdb-dataset" class="section level1">
<h1>Analysis of movies- IMDB dataset</h1>
<p>We will look at a subset sample of movies, taken from the <a href="https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset">Kaggle IMDB 5000 movie dataset</a></p>
<pre class="r"><code>movies &lt;- read_csv(here::here(&quot;data&quot;, &quot;movies.csv&quot;))
glimpse(movies)</code></pre>
<pre><code>## Rows: 2,961
## Columns: 11
## $ title               &lt;chr&gt; &quot;Avatar&quot;, &quot;Titanic&quot;, &quot;Jurassic World&quot;, &quot;The Avenge…
## $ genre               &lt;chr&gt; &quot;Action&quot;, &quot;Drama&quot;, &quot;Action&quot;, &quot;Action&quot;, &quot;Action&quot;, &quot;…
## $ director            &lt;chr&gt; &quot;James Cameron&quot;, &quot;James Cameron&quot;, &quot;Colin Trevorrow…
## $ year                &lt;dbl&gt; 2009, 1997, 2015, 2012, 2008, 1999, 1977, 2015, 20…
## $ duration            &lt;dbl&gt; 178, 194, 124, 173, 152, 136, 125, 141, 164, 93, 1…
## $ gross               &lt;dbl&gt; 7.61e+08, 6.59e+08, 6.52e+08, 6.23e+08, 5.33e+08, …
## $ budget              &lt;dbl&gt; 2.37e+08, 2.00e+08, 1.50e+08, 2.20e+08, 1.85e+08, …
## $ cast_facebook_likes &lt;dbl&gt; 4834, 45223, 8458, 87697, 57802, 37723, 13485, 920…
## $ votes               &lt;dbl&gt; 886204, 793059, 418214, 995415, 1676169, 534658, 9…
## $ reviews             &lt;dbl&gt; 3777, 2843, 1934, 2425, 5312, 3917, 1752, 1752, 35…
## $ rating              &lt;dbl&gt; 7.9, 7.7, 7.0, 8.1, 9.0, 6.5, 8.7, 7.5, 8.5, 7.2, …</code></pre>
<p>Besides the obvious variables of <code>title</code>, <code>genre</code>, <code>director</code>, <code>year</code>, and <code>duration</code>, the rest of the variables are as follows:</p>
<ul>
<li><code>gross</code> : The gross earnings in the US box office, not adjusted for inflation</li>
<li><code>budget</code>: The movie’s budget</li>
<li><code>cast_facebook_likes</code>: the number of facebook likes cast memebrs received</li>
<li><code>votes</code>: the number of people who voted for (or rated) the movie in IMDB</li>
<li><code>reviews</code>: the number of reviews for that movie</li>
<li><code>rating</code>: IMDB average rating</li>
</ul>
<div id="use-your-data-import-inspection-and-cleaning-skills-to-answer-the-following" class="section level2">
<h2>Use your data import, inspection, and cleaning skills to answer the following:</h2>
<ul>
<li>Are there any missing values (NAs)? Are all entries distinct or are there duplicate entries?</li>
</ul>
<pre class="r"><code>skimr::skim(movies) #get an overview of the dataset</code></pre>
<table style="width: auto;" class="table table-condensed">
<caption>
<span id="tab:unnamed-chunk-2">Table 1: </span>Data summary
</caption>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
movies
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
2961
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
11
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
character
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
empty
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:right;">
whitespace
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
title
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
83
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2907
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
genre
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
director
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1366
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
year
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2.00e+03
</td>
<td style="text-align:right;">
9.95e+00
</td>
<td style="text-align:right;">
1920.0
</td>
<td style="text-align:right;">
2.00e+03
</td>
<td style="text-align:right;">
2.00e+03
</td>
<td style="text-align:right;">
2.01e+03
</td>
<td style="text-align:right;">
2.02e+03
</td>
<td style="text-align:left;">
▁▁▁▂▇
</td>
</tr>
<tr>
<td style="text-align:left;">
duration
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.10e+02
</td>
<td style="text-align:right;">
2.22e+01
</td>
<td style="text-align:right;">
37.0
</td>
<td style="text-align:right;">
9.50e+01
</td>
<td style="text-align:right;">
1.06e+02
</td>
<td style="text-align:right;">
1.19e+02
</td>
<td style="text-align:right;">
3.30e+02
</td>
<td style="text-align:left;">
▃▇▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
gross
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.81e+07
</td>
<td style="text-align:right;">
7.25e+07
</td>
<td style="text-align:right;">
703.0
</td>
<td style="text-align:right;">
1.23e+07
</td>
<td style="text-align:right;">
3.47e+07
</td>
<td style="text-align:right;">
7.56e+07
</td>
<td style="text-align:right;">
7.61e+08
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
budget
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.06e+07
</td>
<td style="text-align:right;">
4.37e+07
</td>
<td style="text-align:right;">
218.0
</td>
<td style="text-align:right;">
1.10e+07
</td>
<td style="text-align:right;">
2.60e+07
</td>
<td style="text-align:right;">
5.50e+07
</td>
<td style="text-align:right;">
3.00e+08
</td>
<td style="text-align:left;">
▇▂▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
cast_facebook_likes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.24e+04
</td>
<td style="text-align:right;">
2.05e+04
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
2.24e+03
</td>
<td style="text-align:right;">
4.60e+03
</td>
<td style="text-align:right;">
1.69e+04
</td>
<td style="text-align:right;">
6.57e+05
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
votes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.09e+05
</td>
<td style="text-align:right;">
1.58e+05
</td>
<td style="text-align:right;">
5.0
</td>
<td style="text-align:right;">
1.99e+04
</td>
<td style="text-align:right;">
5.57e+04
</td>
<td style="text-align:right;">
1.33e+05
</td>
<td style="text-align:right;">
1.69e+06
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
reviews
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.03e+02
</td>
<td style="text-align:right;">
4.94e+02
</td>
<td style="text-align:right;">
2.0
</td>
<td style="text-align:right;">
1.99e+02
</td>
<td style="text-align:right;">
3.64e+02
</td>
<td style="text-align:right;">
6.31e+02
</td>
<td style="text-align:right;">
5.31e+03
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
rating
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
6.39e+00
</td>
<td style="text-align:right;">
1.05e+00
</td>
<td style="text-align:right;">
1.6
</td>
<td style="text-align:right;">
5.80e+00
</td>
<td style="text-align:right;">
6.50e+00
</td>
<td style="text-align:right;">
7.10e+00
</td>
<td style="text-align:right;">
9.30e+00
</td>
<td style="text-align:left;">
▁▁▆▇▁
</td>
</tr>
</tbody>
</table>
<blockquote>
<p>None of the variables have missing values.</p>
</blockquote>
<pre class="r"><code>n_distinct(movies) #count distinct movie titles</code></pre>
<pre><code>## [1] 2961</code></pre>
<blockquote>
<p>There are no duplicate values as this value matches the number of rows in the table.</p>
</blockquote>
<ul>
<li>Produce a table with the count of movies by genre, ranked in descending order</li>
</ul>
<pre class="r"><code>movies %&gt;%
  group_by(genre) %&gt;% #group by genres
  summarise(count_movies = n_distinct(title)) %&gt;% #count movies
  arrange(desc(count_movies)) #sort in descending order</code></pre>
<pre><code>## # A tibble: 17 × 2
##    genre       count_movies
##    &lt;chr&gt;              &lt;int&gt;
##  1 Comedy               844
##  2 Action               719
##  3 Drama                484
##  4 Adventure            281
##  5 Crime                198
##  6 Biography            135
##  7 Horror               128
##  8 Animation             35
##  9 Fantasy               26
## 10 Documentary           25
## 11 Mystery               15
## 12 Sci-Fi                 7
## 13 Family                 3
## 14 Musical                2
## 15 Romance                2
## 16 Western                2
## 17 Thriller               1</code></pre>
<ul>
<li>Produce a table with the average gross earning and budget (<code>gross</code> and <code>budget</code>) by genre. Calculate a variable <code>return_on_budget</code> which shows how many $ did a movie make at the box office for each $ of its budget. Ranked genres by this <code>return_on_budget</code> in descending order</li>
</ul>
<pre class="r"><code>#creating new table with average gross earning(avg_gross) and budget(avg_budget)
avg_gross_budget &lt;- movies %&gt;%
  group_by(genre) %&gt;%    #group by genre
  summarize(avg_gross = mean(gross), avg_budget= mean(budget)) %&gt;% 
  mutate(return_on_budget = avg_gross/avg_budget) %&gt;%    #calculate return_on_budget
  arrange(desc(return_on_budget))   #order in descending order

avg_gross_budget</code></pre>
<pre><code>## # A tibble: 17 × 4
##    genre        avg_gross avg_budget return_on_budget
##    &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;
##  1 Musical      92084000    3189500          28.9    
##  2 Family      149160478.  14833333.         10.1    
##  3 Western      20821884    3465000           6.01   
##  4 Documentary  17353973.   5887852.          2.95   
##  5 Horror       37713738.  13504916.          2.79   
##  6 Fantasy      42408841.  17582143.          2.41   
##  7 Comedy       42630552.  24446319.          1.74   
##  8 Mystery      67533021.  39218750           1.72   
##  9 Animation    98433792.  61701429.          1.60   
## 10 Biography    45201805.  28543696.          1.58   
## 11 Adventure    95794257.  66290069.          1.45   
## 12 Drama        37465371.  26242933.          1.43   
## 13 Crime        37502397.  26596169.          1.41   
## 14 Romance      31264848.  25107500           1.25   
## 15 Action       86583860.  71354888.          1.21   
## 16 Sci-Fi       29788371.  27607143.          1.08   
## 17 Thriller         2468     300000           0.00823</code></pre>
<ul>
<li>Produce a table that shows the top 15 directors who have created the highest gross revenue in the box office. Don’t just show the total gross amount, but also the mean, median, and standard deviation per director.</li>
</ul>
<pre class="r"><code>#Create new dataframe with top 15 directors
top_directors &lt;- movies %&gt;%
  group_by(director) %&gt;%   #group by director
  # Calculate gross revenue, mean, median and standard deviation per director
  summarize(total_gross = sum(gross), mean = mean(gross), median = median(gross), sd = sd(gross)) %&gt;%
  slice_max(order_by = total_gross, n = 15)  #select top 15 directors with highest revenue

top_directors</code></pre>
<pre><code>## # A tibble: 15 × 5
##    director          total_gross       mean     median         sd
##    &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1 Steven Spielberg   4014061704 174524422. 164435221  101421051.
##  2 Michael Bay        2231242537 171634041. 138396624  127161579.
##  3 Tim Burton         2071275480 129454718.  76519172  108726924.
##  4 Sam Raimi          2014600898 201460090. 234903076  162126632.
##  5 James Cameron      1909725910 318287652. 175562880. 309171337.
##  6 Christopher Nolan  1813227576 226653447  196667606. 187224133.
##  7 George Lucas       1741418480 348283696  380262555  146193880.
##  8 Robert Zemeckis    1619309108 124562239. 100853835   91300279.
##  9 Clint Eastwood     1378321100  72543216.  46700000   75487408.
## 10 Francis Lawrence   1358501971 271700394. 281666058  135437020.
## 11 Ron Howard         1335988092 111332341  101587923   81933761.
## 12 Gore Verbinski     1329600995 189942999. 123207194  154473822.
## 13 Andrew Adamson     1137446920 284361730  279680930. 120895765.
## 14 Shawn Levy         1129750988 102704635.  85463309   65484773.
## 15 Ridley Scott       1128857598  80632686.  47775715   68812285.</code></pre>
<ul>
<li>Finally, ratings. Produce a table that describes how ratings are distributed by genre. We don’t want just the mean, but also, min, max, median, SD and some kind of a histogram or density graph that visually shows how ratings are distributed.</li>
</ul>
<pre class="r"><code># Check
#First, we create a new dataframe with the new columns for min, max, median, standard deviation.
ratings_by_genre &lt;- movies %&gt;%
  group_by(genre) %&gt;%   #group by genre
  summarize(mean = mean(rating), mix = min(rating), max = max(rating), median = median(rating), sd = sd(rating))  #compute values

#Second, we plot the data into a histogram to see how the ratings are distributed. 
plot_ratings &lt;- movies %&gt;% ggplot( aes(x = rating)) + geom_histogram() +facet_wrap(~genre) + labs(x = &quot;Ratings&quot;, y = NULL) 

ratings_by_genre</code></pre>
<pre><code>## # A tibble: 17 × 6
##    genre        mean   mix   max median     sd
##    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 Action       6.23   2.1   9     6.3   1.03 
##  2 Adventure    6.51   2.3   8.6   6.6   1.09 
##  3 Animation    6.65   4.5   8     6.9   0.968
##  4 Biography    7.11   4.5   8.9   7.2   0.760
##  5 Comedy       6.11   1.9   8.8   6.2   1.02 
##  6 Crime        6.92   4.8   9.3   6.9   0.849
##  7 Documentary  6.66   1.6   8.5   7.4   1.77 
##  8 Drama        6.73   2.1   8.8   6.8   0.917
##  9 Family       6.5    5.7   7.9   5.9   1.22 
## 10 Fantasy      6.15   4.3   7.9   6.45  0.959
## 11 Horror       5.83   3.6   8.5   5.9   1.01 
## 12 Musical      6.75   6.3   7.2   6.75  0.636
## 13 Mystery      6.86   4.6   8.5   6.9   0.882
## 14 Romance      6.65   6.2   7.1   6.65  0.636
## 15 Sci-Fi       6.66   5     8.2   6.4   1.09 
## 16 Thriller     4.8    4.8   4.8   4.8  NA    
## 17 Western      5.7    4.1   7.3   5.7   2.26</code></pre>
<pre class="r"><code>plot_ratings</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-7-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="use-ggplot-to-answer-the-following" class="section level2">
<h2>Use <code>ggplot</code> to answer the following</h2>
<ul>
<li>Examine the relationship between <code>gross</code> and <code>cast_facebook_likes</code>. Produce a scatterplot and write one sentence discussing whether the number of facebook likes that the cast has received is likely to be a good predictor of how much money a movie will make at the box office. What variable are you going to map to the Y- and X- axes?</li>
</ul>
<blockquote>
<p>We tried plotting the whole dataset without removing outliers but it did not look right since there were some extremely high values of gross revenue and total Facebook likes of the cast. The code below removes these outliers.
We mapped cast_total_likes on x-axis, and gross revenue on y-axis.</p>
</blockquote>
<pre class="r"><code>outliers_x &lt;- boxplot(movies$cast_facebook_likes, plot = FALSE)$out #selects outliers in likes
outliers_y &lt;- boxplot(movies$gross, plot = FALSE)$out #selects outliers in revenue

movies_new &lt;- movies
movies_new &lt;- movies_new[-which(movies_new$cast_facebook_likes %in% outliers_x),] #removes outliers in facebook likes
movies_new &lt;- movies_new[-which(movies_new$gross %in% outliers_y),]#removes outliers in revenue

# Code for plot with outliers
ggplot(data = movies, aes(x = cast_facebook_likes, y = gross))+
  geom_point(alpha=0.3) +
  geom_smooth(method = &quot;lm&quot;) + 
  theme_bw() +
  labs(title = &quot;Relationship between cast Facebook likes and earnings&quot;, x = &quot;Facebook likes&quot;, y=&quot;Gross earnings&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_fblikes-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Code for plot without outliers
ggplot(data = movies_new, aes(x = cast_facebook_likes, y = gross))+
  geom_point(alpha=0.3) +
  
  geom_smooth(method = &quot;lm&quot;) + 
  
  theme_bw() +
  labs(title = &quot;Relationship between cast Facebook likes and earnings&quot;, x = &quot;Facebook likes&quot;, y=&quot;Gross earnings&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_fblikes-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>movies %&gt;% 
  select(cast_facebook_likes, gross) %&gt;% 
  cor()</code></pre>
<pre><code>##                     cast_facebook_likes gross
## cast_facebook_likes               1.000 0.213
## gross                             0.213 1.000</code></pre>
<blockquote>
<p>It seems like the number of facebook likes is not a good predictor of the future movie revenue - there is no clear trend between this two variables. The correlation coefficient is 0.2 which is quite low underlining the fact that gross revenue and total facebook likes have no relationship.</p>
</blockquote>
<ul>
<li>Examine the relationship between <code>gross</code> and <code>budget</code>. Produce a scatterplot and write one sentence discussing whether budget is likely to be a good predictor of how much money a movie will make at the box office.</li>
</ul>
<pre class="r"><code>#produce scatterplot
ggplot(movies, aes(x=gross, y=budget)) + geom_point() +
geom_smooth(method = &quot;lm&quot;) +  theme_bw()+ labs(title = &quot;Relationship between gross revenue and budget &quot;, x = &quot;Gross profit&quot;, y=&quot;Budget&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_budget-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>movies %&gt;% 
  select(budget, gross) %&gt;% 
  cor()</code></pre>
<pre><code>##        budget gross
## budget  1.000 0.641
## gross   0.641 1.000</code></pre>
<blockquote>
<p>We can see that there is a correlation between budget spent on a movie and revenue. However, we a couple of movies required a high investment but generated low revenues. This is probably because the producers expected a higher return on investment but the movie wasn’t as popular as expected. Even the correlation value (0.62) supports the claim above.</p>
</blockquote>
<ul>
<li>Examine the relationship between <code>gross</code> and <code>rating</code>. Produce a scatterplot, faceted by <code>genre</code> and discuss whether IMDB ratings are likely to be a good predictor of how much money a movie will make at the box office. Is there anything strange in this dataset?</li>
</ul>
<pre class="r"><code>#produce scatterplot
library(ggforce)
ggplot(movies, mapping =aes(x=rating, y=gross)) +
  geom_point() +
  facet_wrap(~genre, ncol=6) + theme_bw() + labs(title=&quot;Relationship between gross and rating&quot;, x=&quot;Ratings on IMDB&quot;, y=&quot;Gross revenue&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_rating-1.png" width="648" style="display: block; margin: auto;" /></p>
<blockquote>
<p>There is some correlation between ratings and gross earnings: better ratings lead to better earnings. However, movies with lower earnings usually have more variation in ratings, which might be because those movies are either arthouse (higher ratings, critically acclaimed), but not meant for everyone, or just plain bad. Movies with larger earnings have less variation in ratings, probably because when a movie has higher rating, more people are interested in watching it and it earns more as a result.
There is high variation in earnings among the movies with high ratings, which means that a great movie does not necessarily earn much.
What looks strange to us is that earnings depend on whether a movie appeals to a wider audience, because that larger audience would go to the cinemas and make a movie a financial success. IMDb ratings are also made by users, so it seems like it should be more correlation between ratings and gross revenue. The possible explanation might be that users that a small group of users who saw the movie in the cinema rated it highly and other users saw the movie at home, so earnings for the movie are smaller because not many people watched it at the time when it came out.
Also, there are fewer data points for some genres like Thriller, Western etc which leads to ambiguity in drawing any conclusions for these.</p>
</blockquote>
</div>
</div>
<div id="returns-of-financial-stocks" class="section level1">
<h1>Returns of financial stocks</h1>
<blockquote>
<p>You may find useful the material on <a href="https://mam2023.netlify.app/reference/finance_data/">finance data sources</a>.</p>
</blockquote>
<pre class="r"><code>nyse &lt;- read_csv(here::here(&quot;data&quot;,&quot;nyse.csv&quot;))</code></pre>
<p>Based on this dataset, create a table and a bar plot that shows the number of companies per sector, in descending order</p>
<pre class="r"><code># data creation
sector_distribution &lt;- nyse %&gt;%
                       group_by(sector) %&gt;% # group at sector level
                       summarise(count_companies = n()) %&gt;% # calculate number of companies per sector
                       arrange((desc(count_companies))) # order sector by number of companies

# plot graph 
ggplot(data = sector_distribution) +
  aes(x = count_companies, y = fct_reorder(sector, count_companies, .desc = FALSE)) +
  geom_col() + labs(x = &quot;Count of Companies&quot;, y = &quot;Sector&quot;, title = &quot;Number of companies per sector&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/companies_per_sector-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Next, let’s choose some stocks and their ticker symbols and download some data. You <strong>MUST</strong> choose 6 different stocks from the ones listed below; You should, however, add <code>SPY</code> which is the SP500 ETF (Exchange Traded Fund).</p>
<pre class="r"><code># Notice the cache=TRUE argument inthe chunk options. Because getting data is time consuming, 
# cache=TRUE means that once it downloads data, the chunk will not run again next time you knit your Rmd

myStocks &lt;- c(&quot;AAPL&quot;,&quot;JPM&quot;,&quot;DIS&quot;,&quot;DPZ&quot;,&quot;ANF&quot;,&quot;TSLA&quot;,&quot;XOM&quot;,&quot;SPY&quot; ) %&gt;%
  tq_get(get  = &quot;stock.prices&quot;,
         from = &quot;2011-01-01&quot;,
         to   = &quot;2022-08-31&quot;) %&gt;%
  group_by(symbol) 

glimpse(myStocks) # examine the structure of the resulting data frame</code></pre>
<pre><code>## Rows: 23,480
## Columns: 8
## Groups: symbol [8]
## $ symbol   &lt;chr&gt; &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL…
## $ date     &lt;date&gt; 2011-01-03, 2011-01-04, 2011-01-05, 2011-01-06, 2011-01-07, …
## $ open     &lt;dbl&gt; 11.6, 11.9, 11.8, 12.0, 11.9, 12.1, 12.3, 12.3, 12.3, 12.4, 1…
## $ high     &lt;dbl&gt; 11.8, 11.9, 11.9, 12.0, 12.0, 12.3, 12.3, 12.3, 12.4, 12.4, 1…
## $ low      &lt;dbl&gt; 11.6, 11.7, 11.8, 11.9, 11.9, 12.0, 12.1, 12.2, 12.3, 12.3, 1…
## $ close    &lt;dbl&gt; 11.8, 11.8, 11.9, 11.9, 12.0, 12.2, 12.2, 12.3, 12.3, 12.4, 1…
## $ volume   &lt;dbl&gt; 4.45e+08, 3.09e+08, 2.56e+08, 3.00e+08, 3.12e+08, 4.49e+08, 4…
## $ adjusted &lt;dbl&gt; 10.05, 10.10, 10.18, 10.18, 10.25, 10.44, 10.42, 10.50, 10.54…</code></pre>
<p>Financial performance analysis depend on returns; If I buy a stock today for 100 and I sell it tomorrow for 101.75, my one-day return, assuming no transaction costs, is 1.75%. So given the adjusted closing prices, our first step is to calculate daily and monthly returns.</p>
<pre class="r"><code>#calculate daily returns
myStocks_returns_daily &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;daily&quot;, 
               type       = &quot;log&quot;,
               col_rename = &quot;daily_returns&quot;,
               cols = c(nested.col))  

#calculate monthly  returns
myStocks_returns_monthly &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;monthly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;monthly_returns&quot;,
               cols = c(nested.col)) 

#calculate yearly returns
myStocks_returns_annual &lt;- myStocks %&gt;%
  group_by(symbol) %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;yearly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;yearly_returns&quot;,
               cols = c(nested.col))</code></pre>
<p>Create a table where you summarise monthly returns for each of the stocks and <code>SPY</code>; min, max, median, mean, SD.</p>
<pre class="r"><code>summarise_monthly_returns &lt;- myStocks_returns_monthly %&gt;%
                             group_by(symbol) %&gt;%
                             summarise(min_monthly_returns = min(monthly_returns),
                                       max_monthly_returns = max(monthly_returns),
                                       mid_monthly_returns = median(monthly_returns),
                                       mean_monthly_returns = mean(monthly_returns),
                                       sd_monthly_returns = STDEV(monthly_returns))

summarise_monthly_returns</code></pre>
<pre><code>## # A tibble: 8 × 6
##   symbol min_monthly_returns max_monthly_returns mid_monthly_r…¹ mean_…² sd_mo…³
##   &lt;chr&gt;                &lt;dbl&gt;               &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 AAPL                -0.181               0.217         0.0230  0.0230   0.0791
## 2 ANF                 -0.421               0.507         0.00105 0.00337  0.146 
## 3 DIS                 -0.186               0.234         0.00725 0.0113   0.0721
## 4 DPZ                 -0.194               0.342         0.0246  0.0270   0.0774
## 5 JPM                 -0.229               0.202         0.0199  0.0119   0.0727
## 6 SPY                 -0.125               0.127         0.0146  0.0106   0.0404
## 7 TSLA                -0.224               0.811         0.0117  0.0501   0.177 
## 8 XOM                 -0.262               0.241         0.00373 0.00756  0.0697
## # … with abbreviated variable names ¹​mid_monthly_returns,
## #   ²​mean_monthly_returns, ³​sd_monthly_returns</code></pre>
<p>Plot a density plot, using <code>geom_density()</code>, for each of the stocks</p>
<pre class="r"><code>ggplot(data = myStocks_returns_monthly) +
  aes(x = monthly_returns, color = symbol) +
  geom_density() +
  facet_wrap(~symbol) + 
  theme(legend.position=&quot;none&quot;) +
  labs(x = &quot;Monthly Return&quot;, y = &quot;Density&quot;, title = &quot;Density plots for different stocks&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/density_monthly_returns-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>What can you infer from this plot? Which stock is the riskiest? The least risky?</p>
<blockquote>
<p>All the plots seems like following normal distribution and most returns of stocks are zero. The most riskiest stock is TSLA as it is most volatile (largest sd).
The least risky one is <strong><em>SPY</em></strong>.</p>
</blockquote>
<p>Finally, make a plot that shows the expected monthly return (mean) of a stock on the Y axis and the risk (standard deviation) in the X-axis. Please use <code>ggrepel::geom_text_repel()</code> to label each stock</p>
<pre class="r"><code>ggplot(data = summarise_monthly_returns) +
  aes(x=sd_monthly_returns, y=mean_monthly_returns, color=symbol, label=symbol) + 
  geom_point() + 
  theme(legend.position=&quot;none&quot;) +
  ggrepel::geom_text_repel() + labs(x = &quot;Risk (sd)&quot;, y = &quot;Expected monthly returns&quot;, title = &quot;Expected monthly return of Stocks&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/risk_return_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>What can you infer from this plot? Are there any stocks which, while being riskier, do not have a higher expected return?</p>
<blockquote>
<p>From the above graph one can conclude that risk and returns do not go hand in hand. In this plot, TSLA has the highest reward with highest risk.
Compared with JPM, DIS and XOM, DPZ and AAPL are a bit riskier but they do have significantly higher expected return. While ANF is quite risky but does not have high returns and SPY is not that risky but has similar returns as DIS and JPM.</p>
</blockquote>
</div>
<div id="on-your-own-spotify" class="section level1">
<h1>On your own: Spotify</h1>
<p>Spotify have an API, an Application Programming Interface. APIs are ways for computer programs to talk to each other. So while we use Spotify app to look up songs and artists, computers use the Spotify API to talk to the spotify server. There is an R package that allows R to talk to this API: <a href="https://www.rcharlie.com/spotifyr/"><code>spotifyr</code></a>. One of your team members, need to sign up and get a <a href="https://developer.spotify.com/dashboard/">Spotify developer account</a> and then you can download data about one’s Spotify usage. A detailed article on how to go about it can be found here <a href="https://towardsdatascience.com/explore-your-activity-on-spotify-with-r-and-spotifyr-how-to-analyze-and-visualize-your-stream-dee41cb63526">Explore your activity on Spotify with R and <em>spotifyr</em></a></p>
<p>If you do not want to use the API, you can download a sample of over 32K songs by having a look at <a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md" class="uri">https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md</a></p>
<pre class="r"><code>spotify_songs &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv&#39;)</code></pre>
<p>The data dictionary can be found below</p>
<table>
<colgroup>
<col width="17%" />
<col width="17%" />
<col width="64%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>variable</strong></th>
<th><strong>class</strong></th>
<th><strong>description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>track_id</td>
<td>character</td>
<td>Song unique ID</td>
</tr>
<tr class="even">
<td>track_name</td>
<td>character</td>
<td>Song Name</td>
</tr>
<tr class="odd">
<td>track_artist</td>
<td>character</td>
<td>Song Artist</td>
</tr>
<tr class="even">
<td>track_popularity</td>
<td>double</td>
<td>Song Popularity (0-100) where higher is better</td>
</tr>
<tr class="odd">
<td>track_album_id</td>
<td>character</td>
<td>Album unique ID</td>
</tr>
<tr class="even">
<td>track_album_name</td>
<td>character</td>
<td>Song album name</td>
</tr>
<tr class="odd">
<td>track_album_release_date</td>
<td>character</td>
<td>Date when album released</td>
</tr>
<tr class="even">
<td>playlist_name</td>
<td>character</td>
<td>Name of playlist</td>
</tr>
<tr class="odd">
<td>playlist_id</td>
<td>character</td>
<td>Playlist ID</td>
</tr>
<tr class="even">
<td>playlist_genre</td>
<td>character</td>
<td>Playlist genre</td>
</tr>
<tr class="odd">
<td>playlist_subgenre</td>
<td>character</td>
<td>Playlist subgenre</td>
</tr>
<tr class="even">
<td>danceability</td>
<td>double</td>
<td>Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.</td>
</tr>
<tr class="odd">
<td>energy</td>
<td>double</td>
<td>Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.</td>
</tr>
<tr class="even">
<td>key</td>
<td>double</td>
<td>The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.</td>
</tr>
<tr class="odd">
<td>loudness</td>
<td>double</td>
<td>The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.</td>
</tr>
<tr class="even">
<td>mode</td>
<td>double</td>
<td>Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.</td>
</tr>
<tr class="odd">
<td>speechiness</td>
<td>double</td>
<td>Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.</td>
</tr>
<tr class="even">
<td>acousticness</td>
<td>double</td>
<td>A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</td>
</tr>
<tr class="odd">
<td>instrumentalness</td>
<td>double</td>
<td>Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.</td>
</tr>
<tr class="even">
<td>liveness</td>
<td>double</td>
<td>Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.</td>
</tr>
<tr class="odd">
<td>valence</td>
<td>double</td>
<td>A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).</td>
</tr>
<tr class="even">
<td>tempo</td>
<td>double</td>
<td>The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.</td>
</tr>
<tr class="odd">
<td>duration_ms</td>
<td>double</td>
<td>Duration of song in milliseconds</td>
</tr>
</tbody>
</table>
<p>In this dataset, there are only 6 types of <code>playlist_genre</code> , but we can still try to perform EDA on this dataset.</p>
<p>Produce a one-page summary describing this dataset. Here is a non-exhaustive list of questions:</p>
<ol style="list-style-type: decimal">
<li>What is the distribution of songs’ popularity (<code>track_popularity</code>). Does it look like a Normal distribution?</li>
</ol>
<pre class="r"><code>plot1 &lt;- ggplot(spotify_songs, aes(x=track_popularity)) +  
  geom_density() + labs(title=&#39;Density Plot of Track Popularity&#39;,x=&#39;Popularity of Track&#39;,y=&#39;Density&#39;)
plot(plot1) ##checking if track popularity is behaving like a normal distribution</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question1-1.png" width="648" style="display: block; margin: auto;" />
&gt;The distribution of ‘track_popularity’ does not follow any particular distribution. It is not a normal distribution. However, a part of the graph, looks like a normal distribution.</p>
<ol start="2" style="list-style-type: decimal">
<li>There are 12 <a href="https://developer.spotify.com/documentation/web-api/reference/object-model/#audio-features-object">audio features</a> for each track, including confidence measures like <code>acousticness</code>, <code>liveness</code>, <code>speechines</code>and <code>instrumentalness</code>, perceptual measures like <code>energy</code>, <code>loudness</code>, <code>danceability</code> and <code>valence</code> (positiveness), and descriptors like <code>duration</code>, <code>tempo</code>, <code>key</code>, and <code>mode</code>. How are they distributed? can you roughly guess which of these variables is closer to Normal just by looking at summary statistics?</li>
</ol>
<pre class="r"><code>summary(spotify_songs)</code></pre>
<pre><code>##    track_id          track_name        track_artist       track_popularity
##  Length:32833       Length:32833       Length:32833       Min.   :  0.0   
##  Class :character   Class :character   Class :character   1st Qu.: 24.0   
##  Mode  :character   Mode  :character   Mode  :character   Median : 45.0   
##                                                           Mean   : 42.5   
##                                                           3rd Qu.: 62.0   
##                                                           Max.   :100.0   
##  track_album_id     track_album_name   track_album_release_date
##  Length:32833       Length:32833       Length:32833            
##  Class :character   Class :character   Class :character        
##  Mode  :character   Mode  :character   Mode  :character        
##                                                                
##                                                                
##                                                                
##  playlist_name      playlist_id        playlist_genre     playlist_subgenre 
##  Length:32833       Length:32833       Length:32833       Length:32833      
##  Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                             
##                                                                             
##                                                                             
##   danceability       energy           key           loudness    
##  Min.   :0.000   Min.   :0.000   Min.   : 0.00   Min.   :-46.4  
##  1st Qu.:0.563   1st Qu.:0.581   1st Qu.: 2.00   1st Qu.: -8.2  
##  Median :0.672   Median :0.721   Median : 6.00   Median : -6.2  
##  Mean   :0.655   Mean   :0.699   Mean   : 5.37   Mean   : -6.7  
##  3rd Qu.:0.761   3rd Qu.:0.840   3rd Qu.: 9.00   3rd Qu.: -4.6  
##  Max.   :0.983   Max.   :1.000   Max.   :11.00   Max.   :  1.3  
##       mode        speechiness     acousticness   instrumentalness
##  Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000   
##  1st Qu.:0.000   1st Qu.:0.041   1st Qu.:0.015   1st Qu.:0.000   
##  Median :1.000   Median :0.062   Median :0.080   Median :0.000   
##  Mean   :0.566   Mean   :0.107   Mean   :0.175   Mean   :0.085   
##  3rd Qu.:1.000   3rd Qu.:0.132   3rd Qu.:0.255   3rd Qu.:0.005   
##  Max.   :1.000   Max.   :0.918   Max.   :0.994   Max.   :0.994   
##     liveness        valence          tempo      duration_ms    
##  Min.   :0.000   Min.   :0.000   Min.   :  0   Min.   :  4000  
##  1st Qu.:0.093   1st Qu.:0.331   1st Qu.:100   1st Qu.:187819  
##  Median :0.127   Median :0.512   Median :122   Median :216000  
##  Mean   :0.190   Mean   :0.511   Mean   :121   Mean   :225800  
##  3rd Qu.:0.248   3rd Qu.:0.693   3rd Qu.:134   3rd Qu.:253585  
##  Max.   :0.996   Max.   :0.991   Max.   :239   Max.   :517810</code></pre>
<pre class="r"><code>st(spotify_songs)  #summary statistics for the spotify songs data</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:question2">Table 2: </span>Summary Statistics
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:left;">
N
</th>
<th style="text-align:left;">
Mean
</th>
<th style="text-align:left;">
Std. Dev.
</th>
<th style="text-align:left;">
Min
</th>
<th style="text-align:left;">
Pctl. 25
</th>
<th style="text-align:left;">
Pctl. 75
</th>
<th style="text-align:left;">
Max
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
track_popularity
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
42.477
</td>
<td style="text-align:left;">
24.984
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
24
</td>
<td style="text-align:left;">
62
</td>
<td style="text-align:left;">
100
</td>
</tr>
<tr>
<td style="text-align:left;">
playlist_genre
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
… edm
</td>
<td style="text-align:left;">
6043
</td>
<td style="text-align:left;">
18.4%
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
… latin
</td>
<td style="text-align:left;">
5155
</td>
<td style="text-align:left;">
15.7%
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
… pop
</td>
<td style="text-align:left;">
5507
</td>
<td style="text-align:left;">
16.8%
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
… r&amp;b
</td>
<td style="text-align:left;">
5431
</td>
<td style="text-align:left;">
16.5%
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
… rap
</td>
<td style="text-align:left;">
5746
</td>
<td style="text-align:left;">
17.5%
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
… rock
</td>
<td style="text-align:left;">
4951
</td>
<td style="text-align:left;">
15.1%
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
danceability
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.655
</td>
<td style="text-align:left;">
0.145
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.563
</td>
<td style="text-align:left;">
0.761
</td>
<td style="text-align:left;">
0.983
</td>
</tr>
<tr>
<td style="text-align:left;">
energy
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.699
</td>
<td style="text-align:left;">
0.181
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.581
</td>
<td style="text-align:left;">
0.84
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
key
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
5.374
</td>
<td style="text-align:left;">
3.612
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
11
</td>
</tr>
<tr>
<td style="text-align:left;">
loudness
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
-6.719
</td>
<td style="text-align:left;">
2.988
</td>
<td style="text-align:left;">
-46.448
</td>
<td style="text-align:left;">
-8.171
</td>
<td style="text-align:left;">
-4.645
</td>
<td style="text-align:left;">
1.275
</td>
</tr>
<tr>
<td style="text-align:left;">
mode
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.566
</td>
<td style="text-align:left;">
0.496
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
speechiness
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.107
</td>
<td style="text-align:left;">
0.101
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.041
</td>
<td style="text-align:left;">
0.132
</td>
<td style="text-align:left;">
0.918
</td>
</tr>
<tr>
<td style="text-align:left;">
acousticness
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.175
</td>
<td style="text-align:left;">
0.22
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.015
</td>
<td style="text-align:left;">
0.255
</td>
<td style="text-align:left;">
0.994
</td>
</tr>
<tr>
<td style="text-align:left;">
instrumentalness
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.085
</td>
<td style="text-align:left;">
0.224
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.005
</td>
<td style="text-align:left;">
0.994
</td>
</tr>
<tr>
<td style="text-align:left;">
liveness
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.19
</td>
<td style="text-align:left;">
0.154
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.093
</td>
<td style="text-align:left;">
0.248
</td>
<td style="text-align:left;">
0.996
</td>
</tr>
<tr>
<td style="text-align:left;">
valence
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
0.511
</td>
<td style="text-align:left;">
0.233
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.331
</td>
<td style="text-align:left;">
0.693
</td>
<td style="text-align:left;">
0.991
</td>
</tr>
<tr>
<td style="text-align:left;">
tempo
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
120.881
</td>
<td style="text-align:left;">
26.904
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
99.96
</td>
<td style="text-align:left;">
133.918
</td>
<td style="text-align:left;">
239.44
</td>
</tr>
<tr>
<td style="text-align:left;">
duration_ms
</td>
<td style="text-align:left;">
32833
</td>
<td style="text-align:left;">
225799.812
</td>
<td style="text-align:left;">
59834.006
</td>
<td style="text-align:left;">
4000
</td>
<td style="text-align:left;">
187819
</td>
<td style="text-align:left;">
253585
</td>
<td style="text-align:left;">
517810
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>## 12 Feature graphs to check if the variables are normally distributed
plot01 &lt;- ggplot(spotify_songs, aes(x=acousticness)) +  
  geom_density()+ labs(title=&#39;Density Plot of Acousticness&#39;,x=&#39;Acousticness&#39;)
plot(plot01)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot02 &lt;- ggplot(spotify_songs, aes(x=liveness)) +  
  geom_density() + labs(title=&#39;Density Plot of liveness&#39;,x=&#39;liveness&#39;)
plot(plot02)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot03 &lt;- ggplot(spotify_songs, aes(x=speechiness)) +  
  geom_density()+ labs(title=&#39;Density Plot of speechines&#39;,x=&#39;speechines&#39;)
plot(plot03)  </code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-3.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot04 &lt;- ggplot(spotify_songs, aes(x=instrumentalness)) +  
  geom_density()+ labs(title=&#39;Density Plot of Instrumentalness&#39;,x=&#39;Instrumentalness&#39;)
plot(plot04)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-4.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot05 &lt;- ggplot(spotify_songs, aes(x=energy)) +  
  geom_density()+ labs(title=&#39;Density Plot of Energy&#39;,x=&#39;Energy&#39;)
plot(plot05)    ##left skewed</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-5.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot06 &lt;- ggplot(spotify_songs, aes(x=loudness)) +  
  geom_density()+ labs(title=&#39;Density Plot of Loudness&#39;,x=&#39;Loudness&#39;)
plot(plot06)    ##left skewed</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-6.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot07 &lt;- ggplot(spotify_songs, aes(x=danceability)) +  
  geom_density()+ labs(title=&#39;Density Plot of Danceability&#39;,x=&#39;Danceability&#39;)
plot(plot07)    ##slightly left skewed</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-7.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot08 &lt;- ggplot(spotify_songs, aes(x=valence)) +  
  geom_density()+ labs(title=&#39;Density Plot of Valence&#39;,x=&#39;Valence&#39;)
plot(plot08)   ##close to normal distribution</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-8.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot09 &lt;- ggplot(spotify_songs, aes(x=duration_ms)) +  
  geom_density()+ labs(title=&#39;Density Plot of Duration&#39;,x=&#39;Duration&#39;)
plot(plot09)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-9.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot10 &lt;- ggplot(spotify_songs, aes(x=tempo)) +  
  geom_density()+ labs(title=&#39;Density Plot of Tempo&#39;,x=&#39;Tempo&#39;)
plot(plot10)  </code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-10.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot11 &lt;- ggplot(spotify_songs, aes(x=key)) +  
  geom_density()+ labs(title=&#39;Density Plot of Key&#39;,x=&#39;Key&#39;)
plot(plot11)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-11.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot12&lt;- ggplot(spotify_songs, aes(x=mode)) +  
  geom_density()+ labs(title=&#39;Density Plot of Mode&#39;,x=&#39;Mode&#39;)
plot(plot12)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question2-12.png" width="648" style="display: block; margin: auto;" />
&gt;We cannot guess if the given variables are closer to normal distribution just by looking at the summary statistics. We will have to plot graphs to see how these the variables are distributed. By plotting the graphs, we can see that ‘energy’,‘danceability’ have left skewed to an extent. However, valence, duration_ms is more closer to a normal curve.</p>
<ol start="3" style="list-style-type: decimal">
<li>Is there any relationship between <code>valence</code> and <code>track_popularity</code>? <code>danceability</code> and <code>track_popularity</code> ?</li>
</ol>
<pre class="r"><code>plot2 &lt;- ggplot(spotify_songs, aes(y=track_popularity, x=valence)) + 
  geom_point() + geom_smooth(lm=model) + labs(title=&#39;Scatter Plot of Track Popularity &amp; Valence&#39;,x=&#39;Valence&#39;,y=&#39;Popularity of Track&#39;)
plot(plot2)  ##checking if any correlation exists between track popularity and valence</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question3-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot2 &lt;- ggplot(spotify_songs, aes(y=track_popularity, x=danceability)) + 
  geom_point() + geom_smooth(lm=model) + labs(title=&#39;Scatter Plot of Track Popularity &amp; Danceability&#39;,x=&#39;Danceability&#39;,y=&#39;Popularity of Track&#39;)
plot(plot2)  ##checking if any correlation exists between track popularity and danceability</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question3-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>spotify_songs %&gt;% 
  select(track_popularity, valence) %&gt;% 
  cor()  ##checking if any correlation exists between track popularity and valence</code></pre>
<pre><code>##                  track_popularity valence
## track_popularity           1.0000  0.0332
## valence                    0.0332  1.0000</code></pre>
<pre class="r"><code>spotify_songs %&gt;% 
  select(track_popularity, danceability) %&gt;% 
  cor()  ##checking if any correlation exists between track popularity and danceability</code></pre>
<pre><code>##                  track_popularity danceability
## track_popularity           1.0000       0.0647
## danceability               0.0647       1.0000</code></pre>
<blockquote>
<p>After plotting the graphs between <code>valence</code> and <code>track_popularity</code> &amp; <code>danceability</code> and <code>track_popularity</code> we can see that there is no correlation between either of those two. Also when we check by the correlation values, we see that the values are 0.06 and 0.03 which is close to 0 and hence there is not correlation between them.</p>
</blockquote>
<ol start="5" style="list-style-type: decimal">
<li><code>mode</code> indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0. Do songs written on a major scale have higher <code>danceability</code> compared to those in minor scale? What about <code>track_popularity</code>?</li>
</ol>
<pre class="r"><code>box1 &lt;- ggplot(spotify_songs, aes(x=mode, y=danceability, group=mode)) +
  geom_boxplot()+ labs(title=&#39;Box Plot of Danceability &amp; Mode&#39;,x=&#39;Mode&#39;,y=&#39;Danceability&#39;)
box1   ##finding if modality has any effect on danceability</code></pre>
<p><img src="/blogs/homework1_files/figure-html/question5-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>box2 &lt;- ggplot(spotify_songs, aes(x=mode, y=track_popularity, group=mode)) +
  geom_boxplot()+ labs(title=&#39;Box Plot of Track Popularity &amp; Mode&#39;,x=&#39;Mode&#39;,y=&#39;Popularity of Track&#39;)
box2  ##finding if modality has any effect on track popularity </code></pre>
<p><img src="/blogs/homework1_files/figure-html/question5-2.png" width="648" style="display: block; margin: auto;" />
&gt;Upon comparing, we see that the medians are very close and the range of values are also close hence we can conclude that scale(mode) does not have any relation to danceability. The same goes for track_popularity as well.</p>
</div>
<div id="challenge-1-replicating-a-chart" class="section level1">
<h1>Challenge 1: Replicating a chart</h1>
<p>The purpose of this exercise is to reproduce a plot using your <code>dplyr</code> and <code>ggplot2</code> skills. It builds on exercise 1, the San Francisco rentals data.</p>
<p>You have to create a graph that calculates the cumulative % change for 0-, 1-1, and 2-bed flats between 2000 and 2018 for the top twelve cities in Bay Area, by number of ads that appeared in Craigslist.</p>
<pre class="r"><code># code to extract top 12 cities
data_chl1 &lt;- rent %&gt;% 
             group_by(city) %&gt;% # grouped at city level
             summarise(classifieds_city = count(city)) %&gt;% # number of listings by city
             mutate(classifieds = classifieds_city/sum(classifieds_city)) %&gt;% #% of listings by city
             slice_max(order_by = classifieds, n = 12) %&gt;% # select top 12 cities by % of listings
             pull(city) #extract

# data creation
target &lt;- c(0, 1, 2) # filter of number of beds
data_chl2 &lt;- rent %&gt;% 
             filter((beds %in% target)&amp;(city %in% data_chl1)) %&gt;% # filter for beds and city
             group_by(city,beds, year) %&gt;% # grouped at city, beds and year level
             summarise(median_price = median(price)) %&gt;% # calculate median prices
             mutate(percentage_change = ((median_price/lag(median_price) - 1))) %&gt;% # calculate % change 
             mutate(cum_sum = cumsum(coalesce(percentage_change, 1))) # cumsum of % change, replace NA with 1

# plot graph
plot_chl1 &lt;- ggplot(data_chl2, aes(x = year, y = cum_sum, colour = city)) + 
             geom_line() + 
             facet_grid(beds ~ city) + 
             scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
             theme(legend.position=&quot;none&quot;, axis.text.x=element_text(angle=90)) +
             labs(title = &quot;Cumulative % change in 0, 1, and 2-bed rentals in Bay Area&quot;, 
                  subtitle = &quot;2000-2018&quot;,
                  x = NULL,
                  y = NULL)

plot_chl1</code></pre>
<p><img src="/blogs/homework1_files/figure-html/challenge_1-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2-2016-california-contributors-plots" class="section level1">
<h1>Challenge 2: 2016 California Contributors plots</h1>
<p>As discussed in class, I would like you to reproduce the plot that shows the top ten cities in highest amounts raised in political contributions in California during the 2016 US Presidential election.</p>
<p><img src="../../images/challenge2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>To get this plot, you must join two dataframes; the one you have with all contributions, and data that can translate zipcodes to cities. You can find a file with all US zipcodes, e.g., here <a href="http://www.uszipcodelist.com/download.html" class="uri">http://www.uszipcodelist.com/download.html</a>.</p>
<p>The easiest way would be to create two plots and then place one next to each other. For this, you will need the <code>patchwork</code> package. <a href="https://cran.r-project.org/web/packages/patchwork/index.html" class="uri">https://cran.r-project.org/web/packages/patchwork/index.html</a></p>
<p>While this is ok, what if one asked you to create the same plot for the top 10 candidates and not just the top two? The most challenging part is how to reorder within categories, and for this you will find Julia Silge’s post on <a href="https://juliasilge.com/blog/reorder-within/">REORDERING AND FACETTING FOR GGPLOT2</a> useful.</p>
<pre class="r"><code># Make sure you use vroom() as it is significantly faster than read.csv()
CA_contributors_2016 &lt;- vroom::vroom(here::here(&quot;data&quot;,&quot;CA_contributors_2016.csv&quot;))

CA_contributions &lt;- CA_contributors_2016 %&gt;% mutate(zip = as.character(zip))

zipcodes &lt;- vroom::vroom(here::here(&quot;data&quot;,&quot;zip_code_database.csv&quot;))

CA_zip &lt;- left_join(CA_contributions, zipcodes, by = &quot;zip&quot;)

hillary &lt;- CA_zip %&gt;%
              filter(cand_nm == &quot;Clinton, Hillary Rodham&quot;) %&gt;% #filter by candidate name
              group_by(cand_nm, primary_city) %&gt;% #group at candidate and city level
              summarize(cont = sum(contb_receipt_amt)) %&gt;% #sum of amount contributed
              top_n(cont, n = 10) %&gt;% #slice for top 10
              mutate(primary_city = fct_reorder(primary_city, cont)) %&gt;% #reorder city according to contribution
              ggplot(mapping = aes(x = cont, y = primary_city)) + #plotting
              geom_col(fill = &quot;light blue&quot;) + #colour
              scale_x_continuous(labels = scales::dollar_format()) + 
              labs(title = &quot;Clinton, Hillary Rodham&quot;) +
              theme(axis.title.x = element_blank(),
                    axis.title.y = element_blank())

trump &lt;- CA_zip %&gt;%
              filter(cand_nm == &quot;Trump, Donald J.&quot;) %&gt;%
              group_by(cand_nm, primary_city) %&gt;%
              summarize(cont = sum(contb_receipt_amt)) %&gt;%
              top_n(cont, n = 10) %&gt;%
              mutate(primary_city = fct_reorder(primary_city, cont)) %&gt;%
              ggplot(mapping = aes(x = cont, y = primary_city)) +
              geom_col(fill = &quot;light green&quot;) +
              scale_x_continuous(labels = scales::dollar_format()) + 
              labs(title = &quot;Trump, Donald J.&quot;) +
              theme(axis.title.x = element_blank(), 
                    axis.title.y = element_blank()) 

hillary + trump +
  plot_annotation(title = &quot;Where did candidates raise most money?&quot;,
                  caption = &quot;Amount raised&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/load_CA_data_1-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Plots for top 10 candidates
ten_list &lt;- CA_zip %&gt;%
          group_by(cand_nm) %&gt;%
          summarize(cont = sum(contb_receipt_amt)) %&gt;%
          top_n(cont, n = 10)

ten &lt;- CA_zip %&gt;%
        filter(cand_nm == ten_list$cand_nm) %&gt;%
        group_by(cand_nm, primary_city) %&gt;%
        summarize(cont = sum(contb_receipt_amt)) %&gt;%
        top_n(cont, n = 10) %&gt;%
        mutate(primary_city = reorder_within(primary_city, cont, cand_nm)) %&gt;%
        ggplot(mapping = aes(x = cont, y = primary_city, fill = cand_nm)) + 
        geom_col(show.legend = FALSE) + 
        scale_fill_viridis(discrete = TRUE, option = &quot;D&quot;) +
        scale_x_continuous(labels = scales::dollar_format()) + 
        facet_wrap(~cand_nm, scales = &quot;free&quot;) + 
        scale_y_reordered() +
        labs(x = &quot;Amount Raised&quot;,
             y = NULL,
             title = &quot;Where did tep ten candidates raise most money in California? &quot;,
             subtitle = &quot;Based on 2016 Presidential election&quot;)
  
ten</code></pre>
<p><img src="/blogs/homework1_files/figure-html/load_CA_data_2-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Group 5: Arvind Sridhar, Sihan Lu, Sneha Ramteke, Wei Wu, Ioana-Daria Gherghelas, Sofya Lyuleva</li>
<li>Approximately how much time did you spend on this problem set: 9 hours</li>
<li>What, if anything, gave you the most trouble: Compiling everyone’s work and Kintting</li>
</ul>
<blockquote>
<p>As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else? - Yes</p>
</blockquote>
</div>
